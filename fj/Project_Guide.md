# PFLD_GhostOne 项目学习指南

## 1. 项目概况：这个项目是做什么的？

这是一个 **轻量级人脸关键点检测（Face Landmark Detection）** 项目。

*   **核心任务**：输入一张人脸图片，输出人脸上的 98 个关键点坐标（如眼睛、鼻子、嘴巴轮廓等）。
*   **核心特色**：**轻量化与边缘计算**。
    *   原版 PFLD (Practical Facial Landmark Detector) 已经很快，该项目引入了 **GhostNet** 和 **MobileOne** 结构，进一步降低了模型大小（仅 2.7MB 左右），提升了推理速度。
    *   这非常契合你们**微电子/IC 赛道的应用方向**，因为这类模型非常适合部署在算力有限的嵌入式芯片或移动端上。

---

## 2. 核心文件与文件夹功能解析

建议在阅读代码时，按照以下模块划分来理解：

### 2.1 根目录核心脚本
| 文件 | 用途 | 备注 |
| :--- | :--- | :--- |
| `config.py` | **全局配置** | 定义了超参数（学习率、Batch Size）、文件路径等。**改各种参数先看这里。** |
| `train.py` | **训练脚本** | 模型的训练入口，包含训练循环、梯度反向传播等逻辑。 |
| `test.py` | **测试脚本** | 用于在测试集上评估模型精度，计算 NME (Normalized Mean Error)。 |
| `pytorch2onnx.py` | **模型转换** | 将 PyTorch 模型 (`.pth`) 转换为通用的 ONNX 格式，这是落地部署的关键步骤。 |
| `onnx_inference.py` | **推理演示** | 加载转换后的 ONNX 模型进行推理，模拟真实落地场景。 |
| `requirement.txt` | **环境依赖** | Python 库依赖列表。 |

### 2.2 核心模块 (`models/`)
这是你需要重点阅读的部分，特别是为了理解“轻量化”是怎么做到的。
*   `base_module.py`: 定义了基础积木，如 `MobileOneBlock` 和 `GhostOneBottleneck`。这些是构建轻量级网络的原子单元。
*   `PFLD_GhostOne.py`: 整个网络的架构定义。你会看到它如何组合上述积木。

### 2.3 数据处理 (`dataset/` & `data/`)
*   `dataset/datasets.py`: 定义了 PyTorch 的 `Dataset` 类。包含数据增强逻辑（旋转、加噪、翻转），这对训练鲁棒的模型至关重要。
*   `data/SetPreparation.py`: 数据预处理脚本，用于将原始下载的数据集（WFLW）转换为训练需要的格式。

---

## 3. 建议的学习路径（20天规划）

鉴于你们通过 VGG/ResNet 了解了基础，但没有动手经验，且还要学习另一个项目，建议采用 **"Top-Down"（先跑通，再深究）** 的策略。

### **阶段一：环境搭建与推理体验 (1-2 天)**
*   **目标**：让代码跑起来，看到效果。
*   **动作**：
    1.  配置环境（安装 PyTorch 等）。
    2.  下载作者提供的预训练模型（在 README 中）。
    3.  运行 `onnx_inference.py` 或 `test.py`，随便找张自己的人脸照片，看看输出的关键点效果。
    4.  **复习 ONNX 概念**：简单查阅一下什么是 ONNX，为什么 IC 设计/嵌入式部署通常需要它。

### **阶段二：理解模型架构 (3-5 天)**
*   **目标**：看不懂全部代码没关系，但要看懂网络图。
*   **动作**：
    1.  阅读 `models/PFLD_GhostOne.py`。
    2.  **关键知识点补习**：去搜一下 **"Depthwise Separable Convolution" (深度可分离卷积)** 和 **"GhostNet"** 的原理。这是轻量级网络的核心，也是你们比赛的理论亮点。
    3.  搞清楚输入是什么（比如 `112x112` 的图片），输出是什么（`98` 个点的坐标）。

### **阶段三：数据与训练流 (3-4 天)**
*   **目标**：这部分是 AI 工程中最耗时的部分。
    1.  阅读 `dataset/datasets.py`，看看作者怎么做数据增强的（Flip, Rotate）。
    2.  粗读 `train.py`，了解标准的 PyTorch 训练套路：
        ```python
        for data, label in loader:
            pred = model(data)
            loss = criterion(pred, label)
            loss.backward()
            optimizer.step()
        ```
    3.  如果不复现训练，至少要看懂 `loss.py` 中的损失函数是怎么设计的。PFLD 的 Loss 设计不仅仅是简单的 MSE（均方误差），还考虑了人脸姿态，这是该论文的创新点。

### **阶段四：部署链路 (2-3 天)**
*   **目标**：连接软硬件。
    1.  研究 `pytorch2onnx.py`。
    2.  思考：如果要把这个模型放到一块 FPGA 或 ARM 开发板上，你会怎么做？（答案通常是：PyTorch -> ONNX -> TensorRT/NCNN/Tengine）。

---

## 4. 关于复现的建议

**Q: 有必要从头复现（自己重写代码）吗？**
**A: 没有必要，且时间不够。**
你们只有 20 天还要看两个项目，从零手写一个 PFLD 对于初学者来说不仅难度大，而且容易陷入 debug 的泥潭，导致没时间看核心逻辑。

**Q: 应该如何“复现”？**
建议进行 **"Running Reproduction"（跑通复现）**：
1.  **数据跑通**：下载 WFLW 数据集（如果太大，只取 100 张图片做个小样本集），运行 `SetPreparation.py`。
2.  **训练跑通**：修改 `config.py`，将 Epoch 设得很小（比如 1 或 5），Batch Size 设小，确保 `train.py` 能在你们的电脑上不报错运行，并看到 Loss 下降。
3.  **推理跑通**：使用自己训练出来的（虽然肯定很烂）的模型，走一遍导出 ONNX 的流程。

**Q: 需要哪些知识基础？**
1.  **Python**: 能够看懂类 (`class`) 和继承。
2.  **PyTorch Tensor 操作**: 知道 `shape` 是什么，`NCHW` 是什么。
3.  **卷积神经网络基础**: 知道卷积、池化、全连接层的作用。

**Q: 预计耗时？**
如果只是“跑通”上述流程，**5-7 天** 是合理的。剩下的时间你们可以去对比另一个 Ultralytics 的项目，思考两个项目在架构设计上的不同（Ultralytics 通常更重工程化，结构更复杂）。

**给 IC 赛道选手的特别提示：**
你们的优势在于**硬件理解**。在看这个项目时，多思考：
*   “这个 `Conv2d` 操作如果映射到硬件上，计算量是多少？”
*   “为什么 GhostNet 比普通卷积省计算量？”
这将是你们在比赛中区别于纯 CS 学生的杀手锏。
